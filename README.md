
# Fact Checking Engine

This repository contains a fact-checking engine that evaluates the veracity of a given fact (expressed as an RDF statement) with respect to a reference knowledge graph. The engine assigns a veracity score between `0` (false) and `1` (true) to each fact.

The project leverages a pre-trained TransE model to embed knowledge graph entities and relations into a vector space, combined with a neural network classifier to predict truth values.

---

## How It Works

### `fact_checking_training.ipynb`
This notebook is used for training the classifier and saving the required models for `fact_checking.py`:

1. **Import Libraries**: 
- `torch`, `pykeen`, and `rdflib` are used for neural network training, embedding generation, and RDF parsing.
2. **Load the Training Knowledge Graph**: 
- The reference graph (reference-kg.nt) is parsed into triples.
- The triples are converted into a format suitable for embedding generation and training.
3. **Train the TransE Model**: 
- TransE as a knowledge graph embedding model that learns vector representations for entities and relations is trained.
  - Embedding dimensions are defined.
  - The model is trained on the training triples to minimize an embedding loss function.
4. **Prepare Training Data for the Classifier**:
- Positive samples are taken from the training knowledge graph.
- Negative samples are generated by corrupting triples (e.g., replacing one entity with a random entity).
- Subject, predicate, and object embeddings are concatenated to create input vectors for the classifier.
- Assign `1` to positive samples and `0` to negative samples.
5. **Define the Neural Network Classifier**:
- Input layer:
  - 150 ingoing neurons (concatenated embedding size).
  - 300 outgoing neurons.
- Hidden layers:
  - 300 ingoing neurons.
  - 100 outgoing neurons.
- Output layer:
  - 100 ingoing neurons.
  - 1 outgoing neuron (one veracity value).
6. **Train the Classifier**:
- The training dataset is split into training and validation subsets.
- A binary cross-entropy loss function and an optimizer are used.
- Model is trained for multiple epochs, evaluating on the validation set to prevent overfitting.
7. **Save the Models**:
- The trained TransE embeddings and classifier is saved for later use in fact_checking.py.

### `fact_checking.py`
This script is executed from the command line to evaluate RDF statements:

1. **Import Libraries**: 
- `torch`: For handling tensors and neural network computations.
- `argparse`: For command-line argument parsing.
- `pykeen.triples`: For handling triples in a knowledge graph.
- `rdflib`: For parsing and managing RDF data.
2. **Define the `main` Function**: 
- The `main` function orchestrates the fact-checking process and is called on program start:
  - `input_file`: Path to the RDF file containing statements/facts.
  - `output_file`: (Optional) Specifies where to save the results.
3. **Load the Reference Knowledge Graph**: 
- Uses `pykeen.triples.TriplesFactory` to load triples from `trans-e-embeddings/training_triples`. This represents the reference knowledge graph that maps entities and relations to unique IDs.
4. **Load the Pre-Trained TransE Model**:
- The TransE model, saved during training, is loaded using `torch.load`. It contains pre-trained entity and relation embeddings.
5. **Prepare the Neural Network Classifier**:
- Defines a 3-layer feedforward neural network (`torch.nn.Sequential`) as described for `fact_checking_training.ipynb`.
- The classifier is loaded from `fact_checking_model.pt`.
6. **Parse the Input RDF Graph**:
- The RDF graph from the `input_file` is parsed using `rdflib.Graph()`.
- Extracts triples (`subject`, `predicate`, `object`) using RDF-specific vocabulary.
7. **Convert Triples to Embeddings**:
- Each triple is converted to embeddings:
  - IDs for subject, predicate, object are fetched from the reference graph.
  - Embeddings for these IDs are obtained from the TransE model.
  - The embeddings are concatenated into a single vector for classification.
8. **Predict Veracity Scores**:
- All processed triples are stacked into a tensor.
- The classifier, in evaluation mode, predicts scores for the triples using a sigmoid activation to produce values in `[0, 1]`.
9. **Write Results to TTL File**:
- Results are written in RDF/Turtle format, associating each statement's IRI with a truth value.
---

## Setup and Usage

### 0. Prerequisites

Before you begin, ensure you have the following installed:

- **Python 3.11**
- Required Python packages:
  - `torch`
  - `rdflib`
  - `pykeen`

Install the necessary packages by running:

```bash
pip install torch rdflib pykeen
```

### 1. Clone the Repository

```bash
git clone https://github.com/jannes-upb/FoKG_Mini_Project.git
cd fact-checking-engine
```

### 2. Prepare the Models and Data

- Ensure the following files are in the project directory:
  - `classifier/fact_checking_model.pt`: Trained classifier.
  - `trans-e-embeddings/training_triples`: Training triples file.
  - `trans-e-embeddings/trained_model.pkl`: Pre-trained TransE model.

### 3. Run the Engine

The fact-checking script is executed from the command line:

```bash
python fact_checking.py <input_rdf_statements> [--output_file <output_ttl_file>]
```

- **`<input_rdf_statements_nt_file>`**: Path to the nt file containing the RDF statements to be evaluated.
- **`<output_ttl_file>`** (optional): Path to the output TTL file. Default is `predictions.ttl` in the project directory.

#### Example:

Evaluate the test RDF statements in `fokg-sw-test-2024.nt` and save results to `test_predictions.ttl`:

```bash
python .\fact_checking.py .\data\fokg-sw-test-2024.nt --output_file .\test_predictions.ttl
```

### 4. Output Format

The predictions are written to a TTL file containing a single line for each of the facts in the input file.
The lines have the following format:

```ttl
<fact-IRI> <http://swc2017.aksw.org/hasTruthValue> "value"^^<http://www.w3.org/2001/XMLSchema#double> .
```
The fact IRI is the IRI of the RDF statement, e.g.;

http://dice-research.org/data/fb15k-237.ttl#0

The predicate is always the same. The value between the two quotation marks is the result of your fact checking algorithm as double value.