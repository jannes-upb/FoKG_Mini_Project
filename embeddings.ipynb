{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import rdflib\n",
    "from rdflib import URIRef\n",
    "from rdflib import RDF\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference_knowledge_graph = rdflib.Graph()\n",
    "# reference_knowledge_graph.parse(\"data/reference-kg.nt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to pykeen format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference_data_numpy = np.array([(s, p, o) for s, p, o in reference_knowledge_graph])\n",
    "# reference_data_pykeen = TriplesFactory.from_labeled_triples(reference_data_numpy)\n",
    "# reference_data_pykeen.create_inverse_triples = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a new model, execute the two cells above instead of this one\n",
    "reference_data_pykeen = TriplesFactory.from_path_binary(\"transe-embeddings/training_triples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, testing, validation = reference_data_pykeen.split([0.8, 0.1, 0.1])\n",
    "\n",
    "# result = pipeline(\n",
    "#     training=training,\n",
    "#     testing=testing,\n",
    "#     validation=validation,\n",
    "#     model='TransE',\n",
    "#     model_kwargs={\n",
    "#         'embedding_dim': 50,\n",
    "#     },\n",
    "#     epochs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a new model, execute the cell above instead of this one\n",
    "model = torch.load(\"transe-embeddings/trained_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = rdflib.Graph()\n",
    "train.parse(\"data/fokg-sw-train-2024.nt\")\n",
    "\n",
    "test = rdflib.Graph()\n",
    "test.parse(\"data/fokg-sw-test-2024.nt\")\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for statement in train.subjects(RDF.type, RDF.Statement):\n",
    "    \n",
    "    subject = train.value(statement, RDF.subject)\n",
    "    predicate = train.value(statement, RDF.predicate)\n",
    "    obj = train.value(statement, RDF.object)\n",
    "\n",
    "    subject_id = reference_data_pykeen.entity_to_id[subject.n3().strip(\"<>\")]\n",
    "    predicate_id = reference_data_pykeen.relation_to_id[predicate.n3().strip(\"<>\")]\n",
    "    obj_id = reference_data_pykeen.entity_to_id[obj.n3().strip(\"<>\")]\n",
    "\n",
    "    subject_tensor = model.entity_representations[0](torch.LongTensor([subject_id]))\n",
    "    predicate_tensor = model.relation_representations[0](torch.LongTensor([predicate_id]))\n",
    "    obj_tensor = model.entity_representations[0](torch.LongTensor([obj_id]))\n",
    "\n",
    "    veracity_score = train.value(statement, URIRef(\"http://swc2017.aksw.org/hasTruthValue\"))\n",
    "    \n",
    "    train_data.append(torch.cat((subject_tensor, predicate_tensor, obj_tensor), dim=1))\n",
    "    train_labels.append(float(veracity_score))\n",
    "\n",
    "split_index = int(len(train_data) * 0.8)\n",
    "\n",
    "X_train = torch.stack(train_data[:split_index])\n",
    "y_train = torch.Tensor(train_labels[:split_index])\n",
    "\n",
    "X_test = torch.stack(train_data[split_index:])\n",
    "y_test = torch.Tensor(train_labels[split_index:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=150, out_features=300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=300, out_features=100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=100, out_features=1),\n",
    ").to(device)\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def accuracy_function(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc\n",
    "\n",
    "optimizer = torch.optim.Adam(params=classifier.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # set model to training mode\n",
    "    classifier.train()\n",
    "\n",
    "    # forward pass\n",
    "    y_logits = classifier(X_train).squeeze() # squeeze to remove extra dimensions\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits)) # logits -> prediction probabilities -> prediction labels\n",
    "  \n",
    "    # calculate loss and accuracy\n",
    "    loss = loss_function(y_logits, y_train) \n",
    "    acc = accuracy_function(y_true=y_train, y_pred=y_pred) \n",
    "\n",
    "    # set gradients to zero\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # set model to testing mode\n",
    "    classifier.eval()\n",
    "    with torch.inference_mode():\n",
    "        # predict labels\n",
    "        test_logits = classifier(X_test).squeeze() \n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        # calculate loss and accuracy\n",
    "        test_loss = loss_function(test_logits, y_test)\n",
    "        test_acc = accuracy_function(y_true=y_test, y_pred=test_pred)\n",
    "\n",
    "    # print stats\n",
    "    print(f\"Epoch: {epoch} | Training Loss: {loss:.5f}, Training Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
